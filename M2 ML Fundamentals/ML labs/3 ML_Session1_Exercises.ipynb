{"cells":[{"cell_type":"markdown","metadata":{"id":"oE6-QYimM4Jv"},"source":["# Machine Learning Session 1 — Exercises Notebook\n","This notebook contains **questions only**. Students must write all code and answers.\n","Topics covered:\n","- AI → ML → DL basics\n","- ML paradigms\n","- Regression & classification\n","- Evaluation metrics\n","- Iris dataset mini project\n","- Clustering, PCA, dimensionality reduction\n"],"id":"oE6-QYimM4Jv"},{"cell_type":"markdown","metadata":{"id":"0hFQSg3PM4Jy"},"source":["## 1. Warm-up & Context Setting\n","**Exercise 1:** Explain the difference between AI, ML, and DL.\n","\n","**Exercise 2:** Fill a table of real-world ML applications.\n"],"id":"0hFQSg3PM4Jy"},{"cell_type":"markdown","metadata":{"id":"EYGFphmdM4J0"},"source":["## 2. Machine Learning Paradigms\n","**Exercise 3:** Describe Supervised, Unsupervised, Semi-supervised, Reinforcement Learning.\n","\n","**Exercise 4:** Match ML paradigms to examples.\n"],"id":"EYGFphmdM4J0"},{"cell_type":"markdown","metadata":{"id":"glRCrrJyM4J0"},"source":["## 3. Regression & Classification\n","**Exercise 5:** Compare Linear vs Polynomial Regression.\n","\n","**Exercise 6:** Why logistic function fits binary classification.\n","\n","**Exercise 7:** Fill in classification algorithm table (Decision Tree, SVM, KNN).\n"],"id":"glRCrrJyM4J0"},{"cell_type":"markdown","metadata":{"id":"WFQxnpNBM4J1"},"source":["## 4. Evaluation Metrics\n","**Exercise 8:** Explain MSE, RMSE, MAE.\n","\n","**Exercise 9:** Compute Accuracy, Precision, Recall, F1 from TP/TN/FP/FN.\n"],"id":"WFQxnpNBM4J1"},{"cell_type":"markdown","metadata":{"id":"ek76b0acM4J1"},"source":["## 5. Hands-on Mini Project — Iris Dataset\n","**Exercise 10:** Train Logistic Regression and Decision Tree on Iris dataset.\n","\n","**Exercise 11 (Optional):** Plot decision boundaries.\n"],"id":"ek76b0acM4J1"},{"cell_type":"markdown","metadata":{"id":"LER44sc7M4J2"},"source":["## 6. Unsupervised Learning — PCA & Clustering\n","**Exercise 12:** Explain PCA.\n","\n","**Exercise 13:** Differences between Hard vs Soft Clustering.\n","\n","**Exercise 14:** Advantages of DBSCAN over K-Means.\n"],"id":"LER44sc7M4J2"},{"cell_type":"markdown","metadata":{"id":"DrUPpywXM4J3"},"source":["## 7. Challenge Exercise — Full ML Workflow\n","**Exercise 15:** Complete ML workflow on any dataset.\n"],"id":"DrUPpywXM4J3"},{"cell_type":"markdown","metadata":{"id":"jA8ZWxS0M4J3"},"source":["## End of Notebook\n","Submit your answers as a `.ipynb` file.\n"],"id":"jA8ZWxS0M4J3"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}