{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# ðŸš€ MNIST Diffusion Model Training (Local)\n",
                "\n",
                "This notebook is adapted for local execution. It covers:\n",
                "- **Forward Diffusion Process** (Adding noise)\n",
                "- **U-Net Architecture** (Predicting noise)\n",
                "- **Training Loop** (Minimizing MSE loss)\n",
                "- **Reverse Diffusion** (Generating new digits)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "import math\n",
                "import os\n",
                "import time\n",
                "import csv\n",
                "from datetime import datetime\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# ------------------------------------------------\n",
                "# Hyperparameters\n",
                "# ------------------------------------------------\n",
                "T = 500              # Total diffusion steps\n",
                "BATCH_SIZE = 128\n",
                "LR = 2e-4\n",
                "EPOCHS = 10          # Suggested 15, lowered for CPU speed\n",
                "USE_CONDITIONAL = True # Model generates specific digits\n",
                "\n",
                "# ------------------------------------------------\n",
                "# Data Loading\n",
                "# ------------------------------------------------\n",
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.5,), (0.5,))\n",
                "])\n",
                "\n",
                "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
                "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
                "\n",
                "print(f\"Dataset loaded. {len(train_ds)} samples.\")"
            ],
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1) Noise Schedule (Beta, Alpha, Alpha_bar)\n",
                "\n",
                "Diffusion works by adding noise according to a schedule. \n",
                "- **Beta (Î²)**: Amount of noise added at each step.\n",
                "- **Alpha (Î±)**: 1 - Î² (amount of Signal kept).\n",
                "- **Alpha_bar (Î±Ì„)**: Cumulative product of alphas (total signal kept up to step t)."
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "def make_beta_schedule(T, beta_start=1e-4, beta_end=0.02):\n",
                "    return torch.linspace(beta_start, beta_end, T)\n",
                "\n",
                "betas = make_beta_schedule(T).to(device)\n",
                "alphas = 1.0 - betas\n",
                "alpha_bars = torch.cumprod(alphas, dim=0).to(device)\n",
                "\n",
                "def q_sample(x0, t, eps):\n",
                "    \"\"\"\n",
                "    Forward Process: x_t = sqrt(alpha_bar_t) * x0 + sqrt(1 - alpha_bar_t) * eps\n",
                "    \"\"\"\n",
                "    a_bar = alpha_bars[t].view(-1, 1, 1, 1)\n",
                "    signal = torch.sqrt(a_bar) * x0\n",
                "    noise = torch.sqrt(1.0 - a_bar) * eps\n",
                "    return signal + noise"
            ],
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 2) Time Embedding\n",
                "\n",
                "Since the U-Net needs to know which step `t` it is cleaning, we encode `t` into a vector using a sinusoidal function (similar to Transformers)."
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "def sinusoidal_time_embedding(timesteps, dim):\n",
                "    half = dim // 2\n",
                "    freqs = torch.exp(\n",
                "        -math.log(10000) * torch.arange(0, half, device=timesteps.device).float() / half\n",
                "    )\n",
                "    args = timesteps.float().unsqueeze(1) * freqs.unsqueeze(0)\n",
                "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=1)\n",
                "    return emb"
            ],
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3) U-Net Components\n",
                "\n",
                "- **ResBlock**: Convolutional block that injects time information.\n",
                "- **Down**: Downsamples the image (28x28 -> 14x14 -> 7x7).\n",
                "- **Up**: Upsamples the image using Transposed Convolutions."
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "class ResBlock(nn.Module):\n",
                "    def __init__(self, in_ch, out_ch, time_dim):\n",
                "        super().__init__()\n",
                "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
                "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
                "        self.time_proj = nn.Linear(time_dim, out_ch)\n",
                "        self.skip = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
                "\n",
                "    def forward(self, x, t_emb):\n",
                "        h = F.silu(self.conv1(x))\n",
                "        time_added = self.time_proj(t_emb).view(-1, h.size(1), 1, 1)\n",
                "        h = h + time_added\n",
                "        h = F.silu(self.conv2(h))\n",
                "        return h + self.skip(x)\n",
                "\n",
                "class Down(nn.Module):\n",
                "    def __init__(self, ch):\n",
                "        super().__init__()\n",
                "        self.down = nn.Conv2d(ch, ch, 4, stride=2, padding=1)\n",
                "    def forward(self, x):\n",
                "        return self.down(x)\n",
                "\n",
                "class Up(nn.Module):\n",
                "    def __init__(self, ch):\n",
                "        super().__init__()\n",
                "        self.up = nn.ConvTranspose2d(ch, ch, 4, stride=2, padding=1)\n",
                "    def forward(self, x):\n",
                "        return self.up(x)"
            ],
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4) U-Net Model Architecture\n",
                "\n",
                "The model architecture that predicts noise from the noisy `x_t`."
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "class UNet(nn.Module):\n",
                "    def __init__(self, in_ch=1, base=128, time_dim=128, num_classes=None):\n",
                "        super().__init__()\n",
                "        self.time_dim = time_dim\n",
                "        self.num_classes = num_classes\n",
                "\n",
                "        if num_classes is not None:\n",
                "            self.label_emb = nn.Embedding(num_classes, time_dim)\n",
                "\n",
                "        self.time_mlp = nn.Sequential(\n",
                "            nn.Linear(time_dim, time_dim * 4),\n",
                "            nn.SiLU(),\n",
                "            nn.Linear(time_dim * 4, time_dim)\n",
                "        )\n",
                "\n",
                "        self.in_conv = nn.Conv2d(in_ch, base, 3, padding=1)\n",
                "\n",
                "        # Encoder\n",
                "        self.rb1 = ResBlock(base, base, time_dim)\n",
                "        self.down1 = Down(base)\n",
                "        self.rb2 = ResBlock(base, base * 2, time_dim)\n",
                "        self.down2 = Down(base * 2)\n",
                "        self.rb3 = ResBlock(base * 2, base * 2, time_dim)\n",
                "\n",
                "        # Bottleneck\n",
                "        self.mid1 = ResBlock(base * 2, base * 4, time_dim)\n",
                "        self.mid2 = ResBlock(base * 4, base * 4, time_dim)\n",
                "        self.mid3 = ResBlock(base * 4, base * 2, time_dim)\n",
                "\n",
                "        # Decoder\n",
                "        self.up1 = Up(base * 2)\n",
                "        self.rb4 = ResBlock(base * 4, base * 2, time_dim)\n",
                "        self.up2 = Up(base * 2)\n",
                "        self.rb5 = ResBlock(base * 3, base, time_dim)\n",
                "\n",
                "        self.out_norm = nn.GroupNorm(8, base)\n",
                "        self.out_conv = nn.Conv2d(base, 1, 3, padding=1)\n",
                "\n",
                "    def forward(self, x, t, y=None):\n",
                "        t_emb = sinusoidal_time_embedding(t, self.time_dim)\n",
                "        t_emb = self.time_mlp(t_emb)\n",
                "\n",
                "        if self.num_classes is not None:\n",
                "            t_emb = t_emb + self.label_emb(y)\n",
                "\n",
                "        x1 = self.rb1(self.in_conv(x), t_emb)\n",
                "        x2 = self.rb2(self.down1(x1), t_emb)\n",
                "        x3 = self.rb3(self.down2(x2), t_emb)\n",
                "\n",
                "        h = self.mid1(x3, t_emb)\n",
                "        h = self.mid2(h, t_emb)\n",
                "        h = self.mid3(h, t_emb)\n",
                "\n",
                "        h = self.up1(h)\n",
                "        h = self.rb4(torch.cat([h, x2], dim=1), t_emb)\n",
                "        h = self.up2(h)\n",
                "        h = self.rb5(torch.cat([h, x1], dim=1), t_emb)\n",
                "\n",
                "        return self.out_conv(F.silu(self.out_norm(h)))"
            ],
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5) Training Loop\n",
                "\n",
                "The model learns to predict the noise $\\epsilon$ added to the image $x_0$.\n",
                "\n",
                "**Note:** Training on a CPU can be slow. Reduced epochs are set by default."
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "model = UNet(in_ch=1, base=128, time_dim=128, num_classes=(10 if USE_CONDITIONAL else None)).to(device)\n",
                "opt = optim.AdamW(model.parameters(), lr=LR)\n",
                "loss_fn = nn.MSELoss()\n",
                "\n",
                "print(\"ðŸš€ Starting Training Loop...\")\n",
                "model.train()\n",
                "loss_hist = []\n",
                "\n",
                "for ep in range(1, EPOCHS + 1):\n",
                "    epoch_losses = []\n",
                "    t0 = time.time()\n",
                "    for i, (x0, y) in enumerate(train_loader, start=1):\n",
                "        x0, y = x0.to(device), y.to(device)\n",
                "        t = torch.randint(0, T, (x0.size(0),), device=device)\n",
                "        eps = torch.randn_like(x0)\n",
                "        xt = q_sample(x0, t, eps)\n",
                "\n",
                "        if USE_CONDITIONAL:\n",
                "            eps_pred = model(xt, t, y=y)\n",
                "        else:\n",
                "            eps_pred = model(xt, t)\n",
                "\n",
                "        loss = loss_fn(eps_pred, eps)\n",
                "        opt.zero_grad()\n",
                "        loss.backward()\n",
                "        opt.step()\n",
                "\n",
                "        loss_hist.append(loss.item())\n",
                "        epoch_losses.append(loss.item())\n",
                "        \n",
                "        if i % 100 == 0:\n",
                "            print(f\"Epoch [{ep}/{EPOCHS}] | Step {i} | Loss: {loss.item():.4f}\")\n",
                "\n",
                "    avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
                "    print(f\"âœ… Epoch {ep} done! Average Loss: {avg_loss:.4f} | Time: {time.time()-t0:.2f}s\")\n",
                "\n",
                "# Save the model locally\n",
                "torch.save(model.state_dict(), \"diffusion_unet_mnist.pth\")\n",
                "print(\"ðŸ’¾ Model saved as diffusion_unet_mnist.pth\")"
            ],
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 6) Image Generation (Reverse Diffusion)\n",
                "\n",
                "Now we use the trained model to generate images from noise."
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "@torch.no_grad()\n",
                "def p_sample(x, t, y=None):\n",
                "    eps_pred = model(x, t, y=y)\n",
                "    beta_t = betas[t[0]]\n",
                "    alpha_t = alphas[t[0]]\n",
                "    alpha_bar_t = alpha_bars[t[0]]\n",
                "    \n",
                "    mean = (1.0 / torch.sqrt(alpha_t)) * (x - (beta_t / torch.sqrt(1.0 - alpha_bar_t)) * eps_pred)\n",
                "    \n",
                "    if t[0] > 0:\n",
                "        z = torch.randn_like(x)\n",
                "        return mean + torch.sqrt(beta_t) * z\n",
                "    return mean\n",
                "\n",
                "@torch.no_grad()\n",
                "def sample(n=16, target_digit=None):\n",
                "    model.eval()\n",
                "    x = torch.randn(n, 1, 28, 28, device=device)\n",
                "    y = torch.full((n,), target_digit, device=device, dtype=torch.long) if target_digit is not None else None\n",
                "    \n",
                "    for t_inv in range(T - 1, -1, -1):\n",
                "        t_batch = torch.full((n,), t_inv, device=device, dtype=torch.long)\n",
                "        x = p_sample(x, t_batch, y=y)\n",
                "    return x"
            ],
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Generate some digits\n",
                "target = 3  # Try changing this digit\n",
                "gen_imgs = sample(16, target_digit=target)\n",
                "\n",
                "plt.figure(figsize=(6,6))\n",
                "for i in range(16):\n",
                "    plt.subplot(4, 4, i+1)\n",
                "    plt.imshow(gen_imgs[i, 0].cpu(), cmap=\"gray\")\n",
                "    plt.axis(\"off\")\n",
                "plt.suptitle(f\"Generated Digits: {target}\")\n",
                "plt.show()"
            ],
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        }
    ]
}