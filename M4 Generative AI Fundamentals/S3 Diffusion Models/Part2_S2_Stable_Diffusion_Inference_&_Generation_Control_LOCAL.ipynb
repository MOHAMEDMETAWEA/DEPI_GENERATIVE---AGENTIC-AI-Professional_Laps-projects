{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Stable Diffusion Inference & Generation Control (Local Version)\n",
                "\n",
                "This notebook has been adapted for local execution, supporting both CPU and CUDA (GPU) devices."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
                        "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using GPU: Tesla T4\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import torch\n",
                "from diffusers import DiffusionPipeline\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "from contextlib import nullcontext\n",
                "\n",
                "# Device Configuration\n",
                "if torch.cuda.is_available():\n",
                "    device = \"cuda\"\n",
                "    dtype = torch.float16\n",
                "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    device = \"cpu\"\n",
                "    dtype = torch.float32\n",
                "    print(\"Using CPU. Note: Generation will be slow.\")\n",
                "\n",
                "model_path = \"./sd15_local\"\n",
                "model_id = \"runwayml/stable-diffusion-v1-5\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading model 'runwayml/stable-diffusion-v1-5' ...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
                        "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
                        "You are not authenticated with the Hugging Face Hub in this notebook.\n",
                        "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b6460dc0d7204b3095b4f9e3881bea8f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "672b882ba00c4a339dd7abf89fdaf630",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "69420fa1be3548ca846b2916614eec7c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
                        "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4f7a0bd4bcd04d0b89d19332dd3b44c7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "dc31ad83a1d849c8af48f23ecdbe1c5c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Loading weights:   0%|          | 0/196 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "CLIPTextModel LOAD REPORT from: /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/text_encoder\n",
                        "Key                                | Status     |  | \n",
                        "-----------------------------------+------------+--+-\n",
                        "text_model.embeddings.position_ids | UNEXPECTED |  | \n",
                        "\n",
                        "Notes:\n",
                        "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b60e675fe11042baa09d01e91dc994e8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Loading weights:   0%|          | 0/396 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "StableDiffusionSafetyChecker LOAD REPORT from: /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/safety_checker\n",
                        "Key                                               | Status     |  | \n",
                        "--------------------------------------------------+------------+--+-\n",
                        "vision_model.vision_model.embeddings.position_ids | UNEXPECTED |  | \n",
                        "\n",
                        "Notes:\n",
                        "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
                    ]
                }
            ],
            "source": [
                "# Load or Download Model\n",
                "if not os.path.exists(model_path):\n",
                "    print(f\"Downloading model '{model_id}' ...\")\n",
                "    pipe = DiffusionPipeline.from_pretrained(\n",
                "        model_id,\n",
                "        torch_dtype=dtype\n",
                "    )\n",
                "    pipe.save_pretrained(model_path)\n",
                "    print(f\"Model saved to {model_path}\")\n",
                "else:\n",
                "    print(f\"Loading model from {model_path} ...\")\n",
                "    pipe = DiffusionPipeline.from_pretrained(\n",
                "        model_path,\n",
                "        torch_dtype=dtype\n",
                "    )\n",
                "\n",
                "pipe = pipe.to(device)\n",
                "print(\"Stable Diffusion ready \\ud83d\\ude80\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_image(pipe, prompt, seed=None, negative_prompt=None, steps=25, cfg=7.5):\n",
                "    if seed is None:\n",
                "        seed = torch.seed()\n",
                "    \n",
                "    # Use a fixed generator for reproducible results if seed is provided\n",
                "    generator = torch.Generator(device=device).manual_seed(seed)\n",
                "    \n",
                "    # Autocast only for CUDA\n",
                "    amp_ctx = torch.autocast(\"cuda\") if device == \"cuda\" else nullcontext()\n",
                "\n",
                "    with torch.inference_mode(), amp_ctx:\n",
                "        result = pipe(\n",
                "            prompt=prompt,\n",
                "            negative_prompt=negative_prompt,\n",
                "            num_inference_steps=steps,\n",
                "            guidance_scale=cfg,\n",
                "            generator=generator,\n",
                "        )\n",
                "    return result.images[0]\n",
                "\n",
                "def show_two_images(img1, title1, img2, title2):\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    \n",
                "    plt.subplot(1, 2, 1)\n",
                "    plt.imshow(img1)\n",
                "    plt.title(title1)\n",
                "    plt.axis(\"off\")\n",
                "    \n",
                "    plt.subplot(1, 2, 2)\n",
                "    plt.imshow(img2)\n",
                "    plt.title(title2)\n",
                "    plt.axis(\"off\")\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Comparison: Randomness (No Seed)\n",
                "\n",
                "Generating two images with the same prompt but without a fixed seed results in different images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt = \"A futuristic AI lab, holographic screens, ultra detailed\"\n",
                "\n",
                "print(\"Generating image 1...\")\n",
                "img1 = generate_image(pipe, prompt)\n",
                "print(\"Generating image 2...\")\n",
                "img2 = generate_image(pipe, prompt)\n",
                "\n",
                "show_two_images(img1, \"Random Seed (Run 1)\", img2, \"Random Seed (Run 2)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Comparison: Reproducibility (With Seed)\n",
                "\n",
                "Providing the same seed ensures the exact same image is generated."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "seed = 42\n",
                "\n",
                "print(\"Generating image 1 with fixed seed...\")\n",
                "img3 = generate_image(pipe, prompt, seed=seed)\n",
                "print(\"Generating image 2 with fixed seed...\")\n",
                "img4 = generate_image(pipe, prompt, seed=seed)\n",
                "\n",
                "show_two_images(img3, f\"Fixed Seed {seed} (Run 1)\", img4, f\"Fixed Seed {seed} (Run 2)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Influence of Negative Prompts\n",
                "\n",
                "Negative prompts allow you to specify what you *don't* want to see in the image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt_nature = \"A beautiful mountain landscape with a clear lake, oil painting style\"\n",
                "neg_prompt = \"trees, forest, green color\"\n",
                "seed = 123\n",
                "\n",
                "print(\"Generating image without negative prompt...\")\n",
                "img5 = generate_image(pipe, prompt_nature, seed=seed)\n",
                "print(\"Generating image with negative prompt...\")\n",
                "img6 = generate_image(pipe, prompt_nature, seed=seed, negative_prompt=neg_prompt)\n",
                "\n",
                "show_two_images(img5, \"No Negative Prompt\", img6, \"With Negative Prompt (No trees)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. CFG Scale (Guidance Scale)\n",
                "\n",
                "CFG scale controls how closely the model follows the prompt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt_cat = \"A cute cat wearing a space suit, digital art\"\n",
                "seed = 777\n",
                "\n",
                "print(\"Generating with CFG=2.0 (Lower guidance)...\")\n",
                "img7 = generate_image(pipe, prompt_cat, seed=seed, cfg=2.0)\n",
                "print(\"Generating with CFG=15.0 (Higher guidance)...\")\n",
                "img8 = generate_image(pipe, prompt_cat, seed=seed, cfg=15.0)\n",
                "\n",
                "show_two_images(img7, \"Low CFG (2.0)\", img8, \"High CFG (15.0)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
