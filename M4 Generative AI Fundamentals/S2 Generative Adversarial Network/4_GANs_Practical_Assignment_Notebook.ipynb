{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Networks (GANs) — Practical Assignment Notebook\n",
        "\n",
        "## Introduction\n",
        "In this notebook, you will practice building and modifying different GAN architectures to understand how image generation works in deep learning. You will start with a basic GAN, then move to DCGAN, Conditional GANs, and finally apply them to new datasets. Each task is designed to strengthen your understanding through hands-on experimentation.\n",
        "\n",
        "By the end of this notebook, you will be able to:\n",
        "- Build and train GAN and DCGAN models\n",
        "- Understand how convolutional layers improve image generation\n",
        "- Control generated outputs using Conditional GANs\n",
        "- Generalize models to new datasets\n",
        "- Interactively generate images based on user input\n",
        "\n",
        "---\n",
        "\n",
        "## Task 1 — Basic GAN Modification (Easy)\n",
        "### Goal\n",
        "Modify the basic GAN model to generate **32×32** images instead of **28×28**.\n",
        "\n",
        "### Steps\n",
        "1. Change the Generator’s last Linear layer to output **1024** values instead of **784**.\n",
        "2. Update the reshaping step to return images of shape **(1, 32, 32)**.\n",
        "3. Modify the Discriminator input layer to accept **1024** features.\n",
        "4. Train the model and visualize generated samples.\n",
        "\n",
        "### Deliverable\n",
        "- Generated 32×32 images\n",
        "- Short explanation of what you changed\n",
        "\n",
        "### What you learn\n",
        "Understanding how architectural dimensions affect model outputs.\n",
        "\n",
        "---\n",
        "\n",
        "## Task 2 — DCGAN Filter Experiment (Medium)\n",
        "### Goal\n",
        "Experiment with different convolution filter sizes in DCGAN.\n",
        "\n",
        "### Steps\n",
        "1. Change Discriminator filters from:\n",
        "   - Conv2d(1 → 64) → Conv2d(64 → 128)\n",
        "   to:\n",
        "   - Conv2d(1 → 32) → Conv2d(32 → 64)\n",
        "2. Retrain the DCGAN.\n",
        "3. Compare image quality and training stability.\n",
        "\n",
        "### Deliverable\n",
        "- Generated images for both configurations\n",
        "- Short comparison paragraph\n",
        "\n",
        "### What you learn\n",
        "Effect of channel capacity on feature learning and image quality.\n",
        "\n",
        "---\n",
        "\n",
        "## Task 3 — Conditional Generation Test (Medium)\n",
        "### Goal\n",
        "Use Conditional DCGAN to generate specific MNIST digits on demand.\n",
        "\n",
        "### Steps\n",
        "1. Train a Conditional DCGAN on MNIST.\n",
        "2. Generate one image for each label (0–9).\n",
        "3. Display them in a single row.\n",
        "\n",
        "### Deliverable\n",
        "- Image grid of requested digits\n",
        "- Code snippet used for conditional generation\n",
        "\n",
        "### What you learn\n",
        "How label conditioning controls the Generator output.\n",
        "\n",
        "---\n",
        "\n",
        "## Task 4 — Change Dataset (Advanced)\n",
        "### Goal\n",
        "Replace MNIST with **Fashion-MNIST** and retrain DCGAN.\n",
        "\n",
        "### Steps\n",
        "1. Replace `datasets.MNIST` with `datasets.FashionMNIST`.\n",
        "2. Train DCGAN with the same architecture.\n",
        "3. Visualize generated clothing items.\n",
        "\n",
        "### Deliverable\n",
        "- Generated Fashion-MNIST samples\n",
        "- Short comment on image quality\n",
        "\n",
        "### What you learn\n",
        "Generalization of GANs to new datasets.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "gkhqmSYN83Q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Task 5 — Conditional Fashion Generator (Advanced)\n",
        "### Goal\n",
        "Build a Conditional DCGAN that generates specific Fashion-MNIST clothing items based on user input.\n",
        "\n",
        "### Fashion-MNIST Label Map\n",
        "| Label | Clothing Item |\n",
        "|--------|--------------|\n",
        "| 0 | T-shirt / Top |\n",
        "| 1 | Trouser |\n",
        "| 2 | Pullover |\n",
        "| 3 | Dress |\n",
        "| 4 | Coat |\n",
        "| 5 | Sandal |\n",
        "| 6 | Shirt |\n",
        "| 7 | Sneaker |\n",
        "| 8 | Bag |\n",
        "| 9 | Ankle boot |\n",
        "\n",
        "### Steps\n",
        "1. Train a Conditional DCGAN on Fashion-MNIST.\n",
        "2. After training, ask the user to input a label (0–9).\n",
        "3. Generate and display the requested clothing image.\n",
        "\n",
        "### Inference Example\n",
        "```python\n",
        "label = int(input(\"Enter Fashion label (0–9): \"))\n",
        "z = torch.randn(1, latent_dim).to(device)\n",
        "label_tensor = torch.tensor([label]).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    img = G(z, label_tensor)\n",
        "\n",
        "plt.imshow(img.squeeze().cpu(), cmap=\"gray\")\n",
        "plt.title(f\"Generated Class: {label}\")\n",
        "plt.axis(\"off\")\n",
        "```\n",
        "\n",
        "### Deliverable\n",
        "- Generated images for labels 0–9\n",
        "- Screenshot of user-input generation\n",
        "- Short reflection on which classes are easier or harder to generate\n",
        "\n",
        "### What you learn\n",
        "Interactive conditional generation and practical GAN deployment logic.\n",
        "\n",
        "---\n",
        "\n",
        "## Final Note\n",
        "Experiment freely. GAN performance depends heavily on architecture, hyperparameters, and training stability. Your goal is not only to make the model work — but to understand why it behaves the way it does.\n",
        "\n",
        "**Good luck — and enjoy teaching machines to draw!"
      ],
      "metadata": {
        "id": "Rb-FamF582Mf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tVcYBtpU9NFG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}