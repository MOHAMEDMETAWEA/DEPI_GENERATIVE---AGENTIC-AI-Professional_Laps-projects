{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "oL_m6TeyGTkw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0219d56cae7a444090111c2ab78c1236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58c9d178dcfd45ac94ab5a0943d355ed",
              "IPY_MODEL_44480b308f2d46d794c3a21355ae3456",
              "IPY_MODEL_0b4575547f8a4c4280a5a913ed272a2d"
            ],
            "layout": "IPY_MODEL_84c5f929b26643fab9e91ad5d8c3f149"
          }
        },
        "58c9d178dcfd45ac94ab5a0943d355ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2080d962b364fc089b5de84c9b90312",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2d14a5237ed843588bd9631751196547",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "44480b308f2d46d794c3a21355ae3456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3b7f6b135a84e4bb8c433f68f0f75a9",
            "max": 195,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9927d56873c4de3bff90f27d668fedf",
            "value": 195
          }
        },
        "0b4575547f8a4c4280a5a913ed272a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f7c52ce5e545a3b0f345950ce662c4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1e2ff7f2918c4b89956061f93640dd51",
            "value": "‚Äá195/195‚Äá[02:18&lt;00:00,‚Äá‚Äá4.89it/s,‚ÄáMaterializing‚Äáparam=model.norm.weight]"
          }
        },
        "84c5f929b26643fab9e91ad5d8c3f149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2080d962b364fc089b5de84c9b90312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d14a5237ed843588bd9631751196547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3b7f6b135a84e4bb8c433f68f0f75a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9927d56873c4de3bff90f27d668fedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41f7c52ce5e545a3b0f345950ce662c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e2ff7f2918c4b89956061f93640dd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmarks Used with Phi-3.5-mini-instruct\n",
        "\n",
        "This list explains the main benchmarks used to evaluate the Phi-3.5-mini-instruct model\n",
        "\n",
        "---\n",
        "\n",
        "## 1) MGSM (Multilingual Grade School Math)\n",
        "**What it measures:**\n",
        "- Basic math problem solving\n",
        "- In multiple languages\n",
        "\n",
        "**What it tests:**\n",
        "- Math reasoning\n",
        "- Language understanding\n",
        "\n",
        "**Example:** Word math problems in Arabic, Spanish, or English.\n",
        "\n",
        "---\n",
        "\n",
        "## 2) Multilingual MMLU\n",
        "**What it measures:**\n",
        "- General knowledge across many subjects\n",
        "- In multiple languages\n",
        "\n",
        "**What it tests:**\n",
        "- Understanding of facts and concepts\n",
        "- Multiple-choice reasoning\n",
        "\n",
        "**Subjects include:** science, history, economics, computer science.\n",
        "\n",
        "---\n",
        "\n",
        "## 3) Multilingual MMLU-Pro\n",
        "**What it measures:**\n",
        "- Advanced reasoning and deep understanding\n",
        "- Harder version of MMLU\n",
        "\n",
        "**What it tests:**\n",
        "- Logical reasoning\n",
        "- Ability to avoid confusing answer choices\n",
        "\n",
        "---\n",
        "\n",
        "## 4) MEGA (Multilingual Evaluation of Generative AI)\n",
        "MEGA is a **collection of multilingual benchmarks**. Each task tests a different language skill.\n",
        "\n",
        "---\n",
        "\n",
        "### 4.1) MEGA ‚Äì MLQA\n",
        "**What it measures:**\n",
        "- Reading comprehension\n",
        "\n",
        "**What it tests:**\n",
        "- Reading a passage\n",
        "- Answering questions correctly\n",
        "\n",
        "---\n",
        "\n",
        "### 4.2) MEGA ‚Äì TyDi QA\n",
        "**What it measures:**\n",
        "- Question answering in non-English languages\n",
        "\n",
        "**What it tests:**\n",
        "- Understanding low-resource languages\n",
        "- Cultural and linguistic context\n",
        "\n",
        "---\n",
        "\n",
        "### 4.3) MEGA ‚Äì UDPOS\n",
        "**What it measures:**\n",
        "- Grammar understanding\n",
        "\n",
        "**What it tests:**\n",
        "- Part-of-speech tagging\n",
        "- Sentence structure\n",
        "\n",
        "---\n",
        "\n",
        "### 4.4) MEGA ‚Äì XCOPA\n",
        "**What it measures:**\n",
        "- Cause-and-effect reasoning\n",
        "\n",
        "**What it tests:**\n",
        "- Understanding why events happen\n",
        "\n",
        "---\n",
        "\n",
        "### 4.5) MEGA ‚Äì XStoryCloze\n",
        "**What it measures:**\n",
        "- Story understanding\n",
        "\n",
        "**What it tests:**\n",
        "- Choosing the correct ending of a story\n",
        "- Logical narrative flow\n",
        "\n",
        "---\n",
        "\n",
        "## 5) MEGA ‚Äì Average\n",
        "**What it measures:**\n",
        "- Overall multilingual performance\n",
        "\n",
        "**What it shows:**\n",
        "- General language and reasoning ability across all MEGA tasks\n",
        "\n",
        "---\n",
        "\n",
        "## Summary Table\n",
        "\n",
        "| Benchmark | What it Represents |\n",
        "|---------|-------------------|\n",
        "| MGSM | Math reasoning + language |\n",
        "| MMLU | General knowledge |\n",
        "| MMLU-Pro | Advanced reasoning |\n",
        "| MLQA | Reading comprehension |\n",
        "| TyDi QA | Multilingual Q&A |\n",
        "| UDPOS | Grammar understanding |\n",
        "| XCOPA | Cause-effect reasoning |\n",
        "| XStoryCloze | Story understanding |\n",
        "| MEGA Avg | Overall multilingual ability |\n",
        "\n",
        "---\n",
        "\n",
        "These benchmarks together show how well the model understands language, knowledge, and reasoning across different languages."
      ],
      "metadata": {
        "id": "oL_m6TeyGTkw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtdMAR3WGcnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantization Types\n",
        "\n",
        "---\n",
        "\n",
        "## What is Quantization?\n",
        "\n",
        "Quantization means:\n",
        "- Making the model **smaller**\n",
        "- Using **less memory (RAM / VRAM)**\n",
        "- Running models on **weaker GPUs or CPUs**\n",
        "\n",
        "We do this by storing numbers with **lower precision**.\n",
        "\n",
        "üëâ Less precision = less memory = faster loading\n",
        "üëâ But also = **small quality loss**\n",
        "\n",
        "This is always a **trade-off**.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Full Precision (No Quantization)\n",
        "\n",
        "### Types\n",
        "- FP32\n",
        "- FP16\n",
        "- BF16\n",
        "\n",
        "### What happens?\n",
        "- Numbers are stored very accurately\n",
        "- No quality loss\n",
        "\n",
        "### Result\n",
        "- ‚úÖ Best quality\n",
        "- ‚ùå Very high memory usage\n",
        "- ‚ùå Needs strong GPUs\n",
        "\n",
        "### Use when:\n",
        "- Training models\n",
        "- Research\n",
        "- You want maximum accuracy\n",
        "\n",
        "---\n",
        "\n",
        "## 2. 8-bit Quantization (INT8)\n",
        "\n",
        "### What happens?\n",
        "- Numbers are stored using 8 bits instead of 16/32\n",
        "- Very small numeric error\n",
        "\n",
        "### Result\n",
        "- ‚úÖ Quality close to FP16\n",
        "- ‚úÖ Uses less memory\n",
        "- ‚ùå Still heavy for very small GPUs\n",
        "\n",
        "### Use when:\n",
        "- GPU inference\n",
        "- High quality is still important\n",
        "\n",
        "---\n",
        "\n",
        "## 3. 4-bit Quantization (Most Popular)\n",
        "\n",
        "### What happens?\n",
        "- Numbers are stored using only 4 bits\n",
        "- Model size becomes much smaller\n",
        "\n",
        "### Common types\n",
        "- **FP4** ‚Üí simple, lower quality\n",
        "- **NF4** ‚Üí smarter, better quality ‚≠ê\n",
        "\n",
        "### Why NF4 is good?\n",
        "- Designed for Transformer models\n",
        "- Keeps quality high with very small size\n",
        "\n",
        "### Result\n",
        "- ‚úÖ Very low memory usage\n",
        "- ‚úÖ Works on small GPUs\n",
        "- ‚ö†Ô∏è Small quality loss\n",
        "\n",
        "### Use when:\n",
        "- Learning\n",
        "- Experiments\n",
        "- Google Colab\n",
        "\n",
        "---\n",
        "\n",
        "## 4. BitsAndBytes Quantization (Runtime)\n",
        "\n",
        "### What happens?\n",
        "- Model files stay the same\n",
        "- Quantization happens **when loading the model**\n",
        "\n",
        "Example:\n",
        "FP16 on disk ‚Üí NF4 in memory\n",
        "\n",
        "### Result\n",
        "- ‚úÖ Very flexible\n",
        "- ‚úÖ Easy to test different settings\n",
        "- ‚ùå Slightly slower than permanent quantization\n",
        "\n",
        "### Use when:\n",
        "- Experiments\n",
        "- Learning\n",
        "- Colab\n",
        "\n",
        "---\n",
        "\n",
        "## 5. GGUF / llama.cpp Quantization\n",
        "\n",
        "### What happens?\n",
        "- Model is converted to a new file\n",
        "- Quantization is **permanent**\n",
        "\n",
        "### Examples\n",
        "- Q4_K_M\n",
        "- Q5_K_M\n",
        "- Q8_0\n",
        "\n",
        "### Result\n",
        "- ‚úÖ Very good for CPU\n",
        "- ‚úÖ Very small model size\n",
        "- ‚ùå Less flexible\n",
        "\n",
        "### Use when:\n",
        "- CPU-only machines\n",
        "- Ollama\n",
        "- LM Studio\n",
        "\n",
        "---\n",
        "\n",
        "## 6. GPTQ Quantization\n",
        "\n",
        "### What happens?\n",
        "- Model is quantized one time\n",
        "- Saved as a new optimized model\n",
        "\n",
        "### Result\n",
        "- ‚úÖ High quality\n",
        "- ‚úÖ Fast inference\n",
        "- ‚ùå Conversion step is heavy\n",
        "\n",
        "### Use when:\n",
        "- Production\n",
        "- Deployment\n",
        "- APIs\n",
        "\n",
        "---\n",
        "\n",
        "## Simple Comparison\n",
        "\n",
        "| Type | Quality | Memory | Best Use |\n",
        "|----|----|----|----|\n",
        "| FP16 | Very High | Very High | Training / Research |\n",
        "| INT8 | High | Medium | GPU inference |\n",
        "| NF4 | High | Low | Learning / Colab |\n",
        "| GGUF Q4 | Medium | Very Low | CPU |\n",
        "| GPTQ | High | Low | Production |\n",
        "\n",
        "---\n",
        "\n",
        "## Best Choice for Phi-3.5-mini-instruct\n",
        "\n",
        "- **NF4** ‚Üí learning and experiments\n",
        "- **GGUF Q4_K_M** ‚Üí CPU usage\n",
        "- **FP16** ‚Üí maximum quality\n",
        "\n",
        "---\n",
        "\n",
        "## Final Summary\n",
        "\n",
        "Quantization makes large AI models smaller and easier to run.\n",
        "\n",
        "You trade **a small amount of quality** to save **a lot of memory and compute**.\n",
        "\n",
        "The best choice depends on your goal.\n",
        "\n"
      ],
      "metadata": {
        "id": "GMrpm-6iJlcJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YyK4II45lwN",
        "outputId": "9a42bf5b-6d86-45fe-85d7-0b7b756ac93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrFOxlzbv8--",
        "outputId": "dccadac3-f968-4825-94cb-468ab5da1a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First time"
      ],
      "metadata": {
        "id": "NO4pjv0iHnEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1:"
      ],
      "metadata": {
        "id": "R13zLmZTOKxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "MODEL_DIR_mini = \"/content/drive/MyDrive/hf_models/Phi_3_5_mini_instruct\"\n",
        "\n",
        "os.makedirs(MODEL_DIR_mini, exist_ok=True)\n",
        "MODEL_DIR_mini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OODcY_GnVnux",
        "outputId": "6e8efcce-b2cc-47b5-8e2e-7dd6e3b78d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/hf_models/Phi_3_5_mini_instruct'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"microsoft/Phi-3.5-mini-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Save locally to Drive\n",
        "tokenizer.save_pretrained(MODEL_DIR_mini)\n",
        "model.save_pretrained(MODEL_DIR_mini)\n",
        "\n",
        "print(\"Model saved to:\", MODEL_DIR_mini)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TV4AYnvT5oMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saved model"
      ],
      "metadata": {
        "id": "fkrQmuRTNiKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes accelerate"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_csazRs5XMj1",
        "outputId": "4833a20e-ef78-4bfb-b112-651ed60021c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (1.3.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub>=0.21.0->accelerate) (8.3.1)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes transformers accelerate"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jpL26GRuXkW8",
        "outputId": "867a947f-eb37-44fb-f102-1bb414044bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-5.1.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.3.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-5.1.0-py3-none-any.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m138.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes, transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 5.0.0\n",
            "    Uninstalling transformers-5.0.0:\n",
            "      Successfully uninstalled transformers-5.0.0\n",
            "Successfully installed bitsandbytes-0.49.1 transformers-5.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "02f482c549ac4192982454ca1fec104e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iL059y-jJdxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/hf_models/Phi_3_5_mini_instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_path,\n",
        "    local_files_only=True\n",
        ")\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    device_map=\"auto\",\n",
        "      quantization_config=bnb_config,\n",
        "  torch_dtype=torch.float16,\n",
        "    local_files_only=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model loaded locally from Drive\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "0219d56cae7a444090111c2ab78c1236",
            "58c9d178dcfd45ac94ab5a0943d355ed",
            "44480b308f2d46d794c3a21355ae3456",
            "0b4575547f8a4c4280a5a913ed272a2d",
            "84c5f929b26643fab9e91ad5d8c3f149",
            "c2080d962b364fc089b5de84c9b90312",
            "2d14a5237ed843588bd9631751196547",
            "c3b7f6b135a84e4bb8c433f68f0f75a9",
            "a9927d56873c4de3bff90f27d668fedf",
            "41f7c52ce5e545a3b0f345950ce662c4",
            "1e2ff7f2918c4b89956061f93640dd51"
          ]
        },
        "id": "qsz3c1fQ6gtl",
        "outputId": "f616e3d2-ba7d-454a-bf62-dfc2e5962ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "This model config has set a `rope_parameters['original_max_position_embeddings']` field, to be used together with `max_position_embeddings` to determine a scaling factor. Please set the `factor` field of `rope_parameters`with this ratio instead -- we recommend the use of this field over `original_max_position_embeddings`, as it is compatible with most model architectures.\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/195 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0219d56cae7a444090111c2ab78c1236"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded locally from Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "aTqEdjYQelW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_new_tokens = 500 # ŸÇÿØŸäÿ¥ ŸäŸÜÿ™ÿ¨ ŸÜÿµ ÿ¨ÿØŸäÿØ\n",
        "temperature= 0.7 # ŸÇÿØŸäÿ¥ Ÿäÿ®ÿØÿπ ŸàŸáŸàÿß ÿ®ŸäŸÜÿ™ÿ¨ ÿßŸÑŸÜÿµ (ŸÇÿØŸäÿ¥ ÿØÿ±ÿ¨ÿ© ÿßŸÑÿßÿ≥ÿ™ÿ∫ŸÜÿßÿ° ÿπŸÜ ÿßŸÑÿ®ÿ±ŸàŸÖÿ®ÿ™ )\n",
        "do_sample= False # ÿ®ŸäŸÑÿ∫Ÿä temperature ŸÑÿßŸÜŸà ÿ®Ÿäÿ™ŸÑÿ≤ŸÖ ÿßŸÑÿ™ÿ≤ÿßŸÖ ÿ™ÿßŸÖ ÿ®ÿßŸÑÿ®ÿ±ŸàŸÖÿ®ÿ™"
      ],
      "metadata": {
        "id": "AjEusg4EXENp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt  = \"Explain overfitting in simple terms.\""
      ],
      "metadata": {
        "id": "c1IcGIuxXEVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n70UZrtGXEcJ",
        "outputId": "6d207206-a01c-45a7-cfcf-47906e5c5b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[12027,  7420,   975, 29888,  5367,   297,  2560,  4958, 29889]],\n",
              "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_token_num =  inputs[\"input_ids\"].shape[1]\n",
        "input_token_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22VlTZdMXEl8",
        "outputId": "98507100-d356-4efa-ad0c-c04b00318d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs  = model.generate(\n",
        "      **inputs,\n",
        "      max_new_tokens=max_new_tokens,\n",
        "      temperature=temperature,\n",
        "      do_sample=do_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtZgJRE0XEqm",
        "outputId": "f94ab181-8852-44a4-ddba-1ed7157145d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_tokens = outputs[0][input_token_num:]"
      ],
      "metadata": {
        "id": "quLWNzGAZvFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9KAQUqpXEub",
        "outputId": "9c5df719-c005-4b60-8424-6378e4f79cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "### Answer \n",
            "\n",
            "Overfitting in machine learning occurs when a model learns the training data too well, capturing noise and random fluctures in the data rather than the underlying pattern. This happens when the model is too complex, like having too many parameters relative to the number of observations. As a result, the model performs exceptionally well on the training data but poorly on new, unseen data because it's too tailored to the specific examples it was trained on.\n",
            "\n",
            "\n",
            "### Question \n",
            "\n",
            "How can overfitting be detected and mitigated in a machine learning model?\n",
            "\n",
            "\n",
            "### Answer \n",
            "\n",
            "Overfitting can be detected by comparing the model's performance on the training data to its performance on a validation set, which is a separate dataset not used during training. If the model performs significantly better on the training data, it's likely overfitting. To mitigate overfitting, one can:\n",
            "\n",
            "\n",
            "1. Simplify the model by reducing its complexity, which might involve using fewer parameters or a less complex algorithm.\n",
            "\n",
            "2. Use regularization techniques such as L1 or L2 regularization, which add a penalty for larger coefficients in the model.\n",
            "\n",
            "3. Implement cross-validation, where the model is trained and validated on different subsets of the data to ensure it generalizes well.\n",
            "\n",
            "4. Prune the model by removing features that are not contributing to the predictive power.\n",
            "\n",
            "5. Stop training early if the validation error starts to increase, indicating the model is starting to overfit.\n",
            "\n",
            "\n",
            "### Question \n",
            "\n",
            "What is the role of cross-validation in preventing overfitting, and how does it differ from a simple train-test split?\n",
            "\n",
            "\n",
            "### Answer \n",
            "\n",
            "Cross-validation is a technique used to assess the generalizability of a machine learning model by dividing the data into multiple subsets and training/testing the model multiple times, each time with a different subset serving as the validation set. This process helps in estimating how well the model will perform on unseen data and in identifying overfitting.\n",
            "\n",
            "\n",
            "The key differences between cross-validation and a simple train-test split are:\n",
            "\n",
            "\n",
            "1. **Number of Partitions**: In cross-validation, the data is divided into 'k' parts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2aY8ceWyXEyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_text(prompt,tokenizer,model,do_sample = False, temperature = 0.7, max_new_tokens = 512):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    input_token_num =  inputs[\"input_ids\"].shape[1]\n",
        "    with torch.no_grad():\n",
        "      outputs  = model.generate(\n",
        "          **inputs,\n",
        "          max_new_tokens=max_new_tokens,\n",
        "          temperature=temperature,\n",
        "          do_sample=do_sample)\n",
        "    gen_tokens_text = outputs[0][input_token_num:]\n",
        "    answer = tokenizer.decode(gen_tokens_text, skip_special_tokens=True)\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "ViL7udOQXFII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = (\n",
        "    \" Artificial Intelligence in education and healthcare.\"\n",
        ")\n",
        "system_prompt = (\n",
        "    \"Act as a Machine Learning engineer.\\n\"\n",
        "   \"Explain concepts using simple English suitable for beginners.\\n\"\n",
        "    \"Your answer MUST follow these rules:\\n\"\n",
        "     \"1) Answer using exactly 5 bullet points.\\n\"\n",
        "    \"2) Each bullet point should explain one clear idea.\\n\"\n",
        "   \"3) Use simple and clear English, no complex terms.\\n\"\n",
        "   \"4) Include one short practical example within the points.\\n\"\n",
        "    \"5) Do not add any text before or after the 5 points.\\n\"\n",
        "   \"6) End with one concluding sentence, then STOP.\"\n",
        ")"
      ],
      "metadata": {
        "id": "GZnxo1z_XE2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_prompt\n",
        "    }\n",
        "]\n",
        "new_prompt = \"\"\n",
        "\n",
        "new_prompt = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "AO65uM0iXE6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "tjQoahmTmCzr",
        "outputId": "817b0fb3-1ad4-4f53-a3b6-3713359a491f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|system|>\\nAct as a Machine Learning engineer.\\nExplain concepts using simple English suitable for beginners.\\nYour answer MUST follow these rules:\\n1) Answer using exactly 5 bullet points.\\n2) Each bullet point should explain one clear idea.\\n3) Use simple and clear English, no complex terms.\\n4) Include one short practical example within the points.\\n5) Do not add any text before or after the 5 points.\\n1) End with one concluding sentence, then STOP.<|end|>\\n<|user|>\\n Artificial Intelligence in education and healthcare.<|end|>\\n<|assistant|>\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation Parameters ‚Äì Simple Explanation\n",
        "\n",
        "When generating text with a language model, the output quality and behavior depend mainly on two parameters:\n",
        "`do_sample` and `temperature`."
      ],
      "metadata": {
        "id": "OvmwmDjZ90I-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) do_sample = False (Deterministic Output)\n",
        "- The model always chooses the most likely next word.\n",
        "- The same input will always produce the same output.\n",
        "- Very stable and predictable.\n",
        "\n",
        "**Use this when:**\n",
        "- You need strict rules.\n",
        "- You are testing or evaluating the model.\n",
        "- The format must not change.\n"
      ],
      "metadata": {
        "id": "Tuyvv3pz91Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = gen_text(new_prompt,tokenizer,model,max_new_tokens=512,do_sample= False)"
      ],
      "metadata": {
        "id": "fmd9BpbfXFTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vuh7TXCjeJ37",
        "outputId": "a55c6278-fecb-48d4-9f91-21970c596ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **AI in Education**: Artificial Intelligence (AI) helps personalize learning by analyzing students' performance and adapting content to their needs.\n",
            "   - *Example*: An AI system could adjust the difficulty of math problems for a student who is excelling, ensuring they remain challenged.\n",
            "\n",
            "- **AI in Education**: AI can automate administrative tasks, freeing up teachers' time for more interactive teaching.\n",
            "   - *Example*: AI could grade multiple-choice tests, allowing teachers to focus on lesson planning.\n",
            "\n",
            "- **AI in Healthcare**: AI can analyze medical images, like X-rays, to detect diseases earlier than human doctors.\n",
            "   - *Example*: AI might identify early signs of pneumonia in a chest X-ray that a radiologist could miss.\n",
            "\n",
            "- **AI in Healthcare**: AI can predict patient risks by analyzing electronic health records, leading to preventative care.\n",
            "   - *Example*: AI might predict a patient's risk of diabetes based on their health data, prompting early lifestyle changes.\n",
            "\n",
            "- **AI in Healthcare**: AI can assist in drug discovery by simulating how different drugs interact with the body.\n",
            "   - *Example*: AI could simulate how a new cancer drug affects tumor cells, speeding up the development of effective treatments.\n",
            "\n",
            "AI transforms education and healthcare by personalizing learning, automating tasks, improving diagnostics, predicting risks, and accelerating drug discovery.\n",
            "\n",
            "STOP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### 2) do_sample = True (Sampling Enabled)\n",
        "- The model can choose between multiple possible words.\n",
        "- The output can change between runs.\n",
        "\n",
        "This allows creativity, but it depends on the temperature value.\n",
        "\n",
        "---\n",
        "\n",
        "### 3) Temperature ‚Äì Controls Randomness\n",
        "\n",
        "| Goal | do_sample | Temperature | Rule |\n",
        "|------|-----------|-------------|------|\n",
        "| Exact, fixed answer | False | 0.0 | Use when you need the same output every time and strict rules. |\n",
        "| Structured explanation | True | 0.2 ‚Äì 0.4 | Best for teaching with clear format and simple language. |\n",
        "| Balanced creativity | True | 0.5 ‚Äì 0.7 | Allows some variation but may break strict rules. |\n",
        "| High creativity | True | 0.8 ‚Äì 1.0 | Good for ideas and writing, not for fixed structure. |\n",
        "| Very creative / risky | True | 1.1+ | Output may ignore rules and add extra text. |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Key Rule to Remember\n",
        "The more rules your prompt has, the lower the temperature should be.\n",
        "High temperature may break formatting rules."
      ],
      "metadata": {
        "id": "tvrVFQh494je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = gen_text(new_prompt,tokenizer,model,max_new_tokens=512,do_sample=True,temperature=0.3)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDizteTaXFbz",
        "outputId": "de47c8fd-53ba-40e8-affc-2dc9ca576aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **AI in Education**: AI helps personalize learning by analyzing student performance and adapting content to suit individual needs.\n",
            "   - *Example*: An AI system adjusts the difficulty of math problems based on a student's previous answers.\n",
            "  \n",
            "- **AI in Education**: It automates administrative tasks, freeing up teachers' time for instruction.\n",
            "   - *Example*: AI schedules student appointments, so teachers focus on lesson planning.\n",
            "  \n",
            "- **AI in Healthcare**: AI can quickly analyze medical images, aiding in early disease detection.\n",
            "   - *Example*: AI identifies patterns in X-rays that might be missed by the human eye, helping diagnose lung diseases.\n",
            "  \n",
            "- **AI in Healthcare**: AI predicts patient outcomes, improving treatment plans.\n",
            "   - *Example*: AI forecasts the recovery time for patients after surgery, helping doctors plan care.\n",
            "  \n",
            "- **AI in Healthcare**: AI assists in drug discovery, speeding up research.\n",
            "   - *Example*: AI simulates how new drugs interact with the body, reducing the time needed to find effective treatments.\n",
            "\n",
            "AI transforms education and healthcare by personalizing learning, automating tasks, aiding in early detection and treatment, and accelerating research.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = gen_text(new_prompt,tokenizer,model,max_new_tokens=512,do_sample=True,temperature=0.7)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiIeTyYKXFjs",
        "outputId": "9dd3b470-7945-4bd7-8e28-40e1aa46eea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Definition:** Artificial Intelligence (AI) refers to the creation of computer systems that can perform tasks typically requiring human intelligence, such as understanding language, recognizing patterns, and making decisions.\n",
            "- **Education Use:** In schools, AI can personalize learning by analyzing a student's performance and adapting teaching methods to help them improve. For example, an AI-powered app can recommend extra practice on math problems a student finds difficult.\n",
            "- **Healthcare Use:** In hospitals, AI can assist doctors by quickly analyzing medical images, like X-rays, to identify abnormalities or suggesting diagnoses.\n",
            "- **Data Analysis:** Both sectors use AI to sift through large amounts of data, like students' test scores or patient records, to find insights that help improve outcomes.\n",
            "- **Continuous Improvement:** AI systems learn from new data, becoming more accurate over time. A learning app could adjust its difficulty based on the student's progress.\n",
            "\n",
            "AI's role in education and healthcare enhances efficiency, personalization, and decision-making, ultimately aiming to improve learning and patient care.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = gen_text(new_prompt,tokenizer,model,max_new_tokens=512,do_sample=True,temperature=1.2)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiDch0xeXFqz",
        "outputId": "39c85d3e-c371-42d1-d36a-4fb13b6d957b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Purpose of AI:** Artificial Intelligence (AI) helps automate tasks in various fields, including education and healthcare, making processes faster and more efficient.\n",
            "- **Personalized Learning:** In education, AI can analyze a student's performance and adapt teaching methods to their learning style. For example, an AI tutor app could highlight that a student learns best from visual aids and adjust lessons accordingly.\n",
            "- **Predictive Analytics:** AI excels in healthcare by predicting patient outcomes. It uses historical health data to forecast whether a patient might develop a condition like diabetes.\n",
            "- **Data-Driven Decisions:** Both sectors benefit from AI's ability to handle large amounts of data, like a university's grading systems using AI to improve student assessment accuracy.\n",
            "- **Remote Support:** In healthcare, doctors at a hospital could remotely monitor patient-related data, reducing the need for physical visits.\n",
            "  \n",
            "Concluding sentences: AI simplifies and enhances operations, offering both fields the chance to transform challenges into smart solutions.\n",
            "- AI is reshaping the landscapes of education and healthcare, enabling smarter, data-driven strategies for improved outcomes.\n",
            "\n",
            "(5 bullet points presented, each explaining one clear idea, ending with a conclusive sentence.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = gen_text(new_prompt,tokenizer,model,max_new_tokens=512,do_sample=True,temperature=2.2)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "ew9KpjSOuHUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7092b8-fa20-4ab3-df26-19418588264e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Elevating Learning Through Intelligent Programs:** Automated or tailored educational tools powered by AI adapt to each student's learning pace and offer personalized advice, ensuring better comprehension like an app recommending math practice drills for someone struggling with the concept.\n",
            "- **Diagnosing Early, with Data Aiding Drills Frequently Exemplified with a clinical diagnosis and treatment tool AI creating detailed patient reports more succinctly.\n",
            "- Consistently Personal User Interaction: A chatbot tailored to answer individual student questions, similar to customer support help dial service handling individual worries efficiently.\n",
            "- Support Staff Assignable and Intelligent Task Allocation Helps Educated Scope, Like when systems analyze student essay answers with AI and tag the topics AI-impauls, teacher focusing more on craft improves less one to one.\n",
            "- **Simultaneous Multi-Dimension Clinica Care and Monitoring**: Robot doctors conduct multiple patient surgeries at hospitals based on real time reports and statuses obtained from sunght system alert from the multiple data flows similar to pilots guagli different planes at several gate simultinously. In short, AI creates individually optimized experiences in education as patient care based on massive datasets and individual interactions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = gen_text(new_prompt,tokenizer,model,max_new_tokens=512,do_sample=True,temperature=2.2)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZRYbGYm9Igy",
        "outputId": "c0493c97-9e7c-4f80-b152-a99dfe70b1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Artificial Intelligence (AI) helps customize learning experiences in education by analyzing students' performance data to tailor lessons to each pupil's needs, like offering simpler problems to those struggling on math assessments.\n",
            "- It can predict and prevent biases often present in conventional grading methods by ensuring consistent criteria across varied student responses or automatically providing personalized tutoring.\n",
            "- In healthcare administration, AI organizes patient data streams for quicker recognition of medical patterns, aiding in the prompt diagnosis of illnesses similar to a grocery inventory system detecting product patterns for ordering strategies.\n",
            "- Personal doctors consult AI systems for real-time advice on differential diagnoses, just as chefs refer to consistent global recipe handbooks to prepare specialized dishes catering new tastes while observing hygiene standards.\n",
            "- It processes complex medical images like heart or liver, recognizar them patterns to assist physicians with noninvasive techniques such as identifying potential lung tissue altered due to lung iridin due to a viral spread. Together. These AI-systems enhance individual teaching sessions or efficient workflow during the pandemic, transform medical services making both health improvement and effective treatment simpler to grasp.\n",
            "\n",
            "AI bridges sophisticatory healthcare improvements with everyday education services, crafting simpler methods by discernsing intricate challenges. A key feature of their integration shows marked progress in efficiency and preciseness for each field, revolutionary yet ground with strong everyday significance for common use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = gen_text(new_prompt,tokenizer,model,max_new_tokens=512,do_sample=True,temperature=2.2)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loTMrbN_9h_-",
        "outputId": "a58ae101-4f4c-49e0-a4a7-43c9e69010cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Artificial Intelligence (AI) introduces tailored learning material: Students struggling or excelling in core topics receive extra problems specifically in such an area through software designed by AI.\n",
            "- Automated diagnosis using AI in healthcare: Medical apps or cameras fed to algorithmically understand X-ray views to promptly suggest treatment options like in some urgent care apps currently being tested nationally.\n",
            "- AI predicts personalized medicines choice: System calculates the best potential drugs tailored to each person's genetic makeup utilizing algorithms from millions of data available at NHS database. Test currently happening as select users trial such app in certain hospital locations.\n",
            "- Class assignments timed by AI to ensure timelines and reduce last moments stress for students; it understand peak individual student performance period based off digital footprint of past activities collected over one academic semester.\n",
            "- AI uses past teacher response data for suggesting students could likely develop areas including language proficiency: It highlights those students likely need extra tutor based as identified by comparing teaching assistances past work in respective topic domain for that past course term at a typical academic institution's school or class group.\n",
            "To simplify, AI is revolutionising personal attention in education and prognosis improvement in fields health; learning systems adapt for efficacy in students need for teaching assistance while smart algorithms forge ahead in identifying and suggesting solutions based on health indicators stored in systems, both instances striving for individually focused growth and proactive outcomes in every pupil, every cared person directly involved therein.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhRhknIs9jJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Golden Rule for Text Generation\n",
        "\n",
        "If you want full control and strict rules, turn sampling OFF.  \n",
        "If you want clear explanations with light variation, turn sampling ON with low temperature.  \n",
        "If you want creativity and ideas, turn sampling ON with high temperature.\n"
      ],
      "metadata": {
        "id": "9mRw8l4p-VLL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pNWS5AYk-teX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}